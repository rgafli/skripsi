# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qh35bX3ukzMzoq3Pgu3QX1MC6G9K8KH8
"""

# 1. Install necessary packages
!pip install transformers scikit-learn joblib

# 2. Create working directory
import os
os.makedirs("sentiment_app/bert-finetuned-superapp", exist_ok=True)

# 3. Download pre-trained BERT model to simulate fine-tuned version
from transformers import BertTokenizer, BertForSequenceClassification

model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=3)
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

model.save_pretrained("sentiment_app/bert-finetuned-superapp")
tokenizer.save_pretrained("sentiment_app/bert-finetuned-superapp")

# 4. Create and save dummy Naive Bayes, SVM, TF-IDF models
import joblib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC

X_dummy = ["good app", "bad app", "average app"]
y_dummy = [2, 0, 1]  # Positive, Negative, Neutral

vec = TfidfVectorizer()
X_vec = vec.fit_transform(X_dummy)

nb = MultinomialNB().fit(X_vec, y_dummy)
svm = SVC(probability=True).fit(X_vec, y_dummy)

joblib.dump(vec, "sentiment_app/tfidf_vectorizer.pkl")
joblib.dump(nb, "sentiment_app/naive_bayes_model.pkl")
joblib.dump(svm, "sentiment_app/svm_model.pkl")

# 5. Save Streamlit app to sentiment_analysis.py
streamlit_code = """
import streamlit as st
import joblib
import torch
from transformers import BertTokenizer, BertForSequenceClassification

LABELS = ["Negative", "Neutral", "Positive"]

@st.cache_resource
def load_nb_model():
    return joblib.load("naive_bayes_model.pkl")

@st.cache_resource
def load_svm_model():
    return joblib.load("svm_model.pkl")

@st.cache_resource
def load_vectorizer():
    return joblib.load("tfidf_vectorizer.pkl")

@st.cache_resource
def load_bert_model():
    model = BertForSequenceClassification.from_pretrained(
        "./bert-finetuned-superapp", local_files_only=True
    )
    tokenizer = BertTokenizer.from_pretrained(
        "./bert-finetuned-superapp", local_files_only=True
    )
    return model, tokenizer

def predict_sentiment(text, model_name):
    if model_name in ["Naive Bayes", "SVM"]:
        vectorizer = load_vectorizer()
        vec_text = vectorizer.transform([text])
        model = load_nb_model() if model_name == "Naive Bayes" else load_svm_model()
        pred = model.predict(vec_text)[0]
        return LABELS[pred]
    elif model_name == "BERT":
        model, tokenizer = load_bert_model()
        model.eval()
        inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
        with torch.no_grad():
            outputs = model(**inputs)
        pred = torch.argmax(outputs.logits, dim=1).item()
        return LABELS[pred]
    return "Unknown"

st.title("üß† Superapp Review Sentiment Analyzer")
st.markdown("Analyze customer feedback using Naive Bayes, SVM, or BERT.")

text_input = st.text_area("‚úçÔ∏è Enter your superapp review:")
model_choice = st.selectbox("üì¶ Choose a model to predict with:", ["Naive Bayes", "SVM", "BERT"])

if st.button("üîç Analyze"):
    if text_input.strip() == "":
        st.warning("Please enter a review first.")
    else:
        try:
            prediction = predict_sentiment(text_input, model_choice)
            if prediction == "Negative":
                st.error(f"Predicted Sentiment: {prediction}")
            elif prediction == "Neutral":
                st.warning(f"Predicted Sentiment: {prediction}")
            else:
                st.success(f"Predicted Sentiment: {prediction}")
        except Exception as e:
            st.exception(f"üö´ Model loading or prediction failed. Error: {e}")
"""

with open("sentiment_app/sentiment_analysis.py", "w") as f:
    f.write(streamlit_code)

# 6. Zip everything
import shutil
shutil.make_archive("sentiment_analyzer_package", "zip", "sentiment_app")